---
--- Generated by EmmyLua(https://github.com/EmmyLua)
--- Created by shuieryin.
--- DateTime: 12/01/2018 8:54 PM
---

function computeNumericalGradient(J, theta)
    --COMPUTENUMERICALGRADIENT Computes the gradient using "finite differences"
    --and gives us a numerical estimate of the gradient.
    --   numgrad = COMPUTENUMERICALGRADIENT(J, theta) computes the numerical
    --   gradient of the function J around theta. Calling y = J(theta) should
    --   return the function value at theta.

    -- Notes: The following code implements numerical gradient checking, and
    --        returns the numerical gradient.It sets numgrad(i) to (a numerical
    --        approximation of) the partial derivative of J with respect to the
    --        i-th input argument, evaluated at theta. (i.e., numgrad(i) should
    --        be the (approximately) the partial derivative of J with respect
    --        to theta(i).)

    local numgrad = torch.zeros(theta:size())
    local perturb = torch.zeros(theta:size())
    local e = 1e-6
    for p = 1, theta:numel() do
        -- Set perturbation vector
        perturb[p] = e
        local loss1 = J(theta - perturb)
        local loss2 = J(theta + perturb)
        -- Compute Numerical Gradient
        numgrad[p] = (loss2 - loss1) / (2 * e)
        perturb[p] = 0
    end
    return numgrad
end